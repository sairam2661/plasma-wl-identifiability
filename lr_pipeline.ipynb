{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cbad70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.lib.format import open_memmap\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae02228c",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2c1196",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f2cd56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data built: (26106, 40921)\n",
      "val data built: (11935, 40921)\n",
      "test data built: (8629, 40921)\n"
     ]
    }
   ],
   "source": [
    "def initialize_sample_memmap_npy():\n",
    "    ref = pd.read_csv('data/patient_timepoints.csv', dtype={'patient_id': str, 'timepoint': int})\n",
    "\n",
    "    feature_cols = ref.columns[2:]\n",
    "    # Scale data with Pareto scaling\n",
    "    feat_df = ref[feature_cols].astype(float)\n",
    "    feat_df = feat_df.div(np.sqrt(feat_df.std()), axis=1)\n",
    "    feat_df = feat_df.div(feat_df.sum(axis=1), axis=0)\n",
    "\n",
    "    # Replace NA's with 0\n",
    "    feat_df = feat_df.fillna(0.0)\n",
    "\n",
    "    # Build lookup on scaled vectors\n",
    "    sample_dict = {\n",
    "        (row['patient_id'].lstrip('0'), row['timepoint']): \n",
    "           feat_df.iloc[i].to_numpy(dtype=np.float32)\n",
    "        for i, row in ref.iterrows()\n",
    "    }\n",
    "\n",
    "    for split in ('train','val','test'):\n",
    "        pairs = pd.read_csv(f'data/{split}_pair_keys.csv',\n",
    "                            dtype={'patient_id_a':str,'timepoint_a':int,\n",
    "                                   'patient_id_b':str,'timepoint_b':int})\n",
    "        n = len(pairs)\n",
    "        feature_dim = len(feature_cols)\n",
    "\n",
    "        X_mm = open_memmap(f'data/{split}_scaled_X.npy', mode='w+', dtype='float32',\n",
    "                           shape=(n, feature_dim))\n",
    "        y_mm = open_memmap(f'data/{split}_scaled_y.npy', mode='w+', dtype='int8',\n",
    "                           shape=(n,))\n",
    "\n",
    "        for i, row in enumerate(pairs.itertuples(index=False)):\n",
    "            a, ta = row.patient_id_a.lstrip('0'), row.timepoint_a\n",
    "            b, tb = row.patient_id_b.lstrip('0'), row.timepoint_b\n",
    "            vec_a = sample_dict[(a, ta)]\n",
    "            vec_b = sample_dict[(b, tb)]\n",
    "            X_mm[i] = np.abs(vec_a - vec_b)\n",
    "            y_mm[i] = 1 if a == b else 0\n",
    "\n",
    "        X_mm.flush(); y_mm.flush()\n",
    "        print(f\"{split} data built: {X_mm.shape}\")\n",
    "\n",
    "initialize_sample_memmap_npy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec126d5b",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14ae85b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load key files to get sizes and feature dimension\n",
    "ref = pd.read_csv('data/patient_timepoints.csv', dtype={'patient_id':str,'timepoint':int})\n",
    "feature_dim = ref.shape[1] - 2\n",
    "\n",
    "train_pairs = pd.read_csv('data/train_pair_keys.csv', dtype={'patient_id_a':str,'timepoint_a':int,'patient_id_b':str,'timepoint_b':int})\n",
    "val_pairs   = pd.read_csv('data/val_pair_keys.csv',   dtype=train_pairs.dtypes.to_dict())\n",
    "test_pairs  = pd.read_csv('data/test_pair_keys.csv',  dtype=train_pairs.dtypes.to_dict())\n",
    "\n",
    "n_train = len(train_pairs)\n",
    "n_val   = len(val_pairs)\n",
    "n_test  = len(test_pairs)\n",
    "\n",
    "# Memory-map the data\n",
    "train_X = np.load('data/train_scaled_X.npy', mmap_mode='r')\n",
    "train_y = np.load('data/train_scaled_y.npy', mmap_mode='r')\n",
    "val_X   = np.load('data/val_scaled_X.npy',   mmap_mode='r')\n",
    "val_y   = np.load('data/val_scaled_y.npy',   mmap_mode='r')\n",
    "test_X  = np.load('data/test_scaled_X.npy',  mmap_mode='r')\n",
    "test_y  = np.load('data/test_scaled_y.npy',  mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6a21785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled X range: 0.0 – 0.3137567\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.load('data/train_scaled_X.npy', mmap_mode='r')\n",
    "print(\"Scaled X range:\", X.min(), \"–\", X.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8a2d30",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33ea5807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 finished\n",
      "Epoch 2/10 finished\n",
      "Epoch 3/10 finished\n",
      "Epoch 4/10 finished\n",
      "Epoch 5/10 finished\n",
      "Epoch 6/10 finished\n",
      "Epoch 7/10 finished\n",
      "Epoch 8/10 finished\n",
      "Epoch 9/10 finished\n",
      "Epoch 10/10 finished\n",
      "Train → Acc: 0.9761, F1: 0.9643\n",
      "Val   → Acc: 0.9842, F1: 0.9763\n",
      "Test  → Acc: 0.9871, F1: 0.9807\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model\n",
    "clf = SGDClassifier(\n",
    "    loss='log_loss',\n",
    "    penalty='l1',\n",
    "    max_iter=1,\n",
    "    learning_rate='optimal',\n",
    "    warm_start=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "batch_size = 1000\n",
    "epochs = 10\n",
    "classes    = np.unique(train_y)\n",
    "\n",
    "# Mini‐batch training\n",
    "for epoch in range(epochs):\n",
    "    for start in range(0, n_train, batch_size):\n",
    "        end = min(start + batch_size, n_train)\n",
    "        Xb = train_X[start:end]\n",
    "        yb = train_y[start:end]\n",
    "        if epoch == 0 and start == 0:\n",
    "            clf.partial_fit(Xb, yb, classes=classes)\n",
    "        else:\n",
    "            clf.partial_fit(Xb, yb)\n",
    "    print(f\"Epoch {epoch+1}/10 finished\")\n",
    "\n",
    "for name, X, y in [('Train', train_X, train_y),\n",
    "                  ('Val',   val_X,   val_y),\n",
    "                  ('Test',  test_X,  test_y)]:\n",
    "    pred = clf.predict(X)\n",
    "    acc   = accuracy_score(y, pred)\n",
    "    f1    = f1_score(y, pred, average='weighted')\n",
    "    print(f\"{name:5} → Acc: {acc:.4f}, F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622839b1",
   "metadata": {},
   "source": [
    "### Inspect features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3275f8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 features:\n",
      "  Feature 19135: coef=-1.4621\n",
      "  Feature 19589: coef=-0.5871\n",
      "  Feature 14798: coef=-0.4500\n",
      "  Feature 21052: coef=-0.3893\n",
      "  Feature 23557: coef=-0.0374\n",
      "  Feature 10894: coef=-0.0252\n",
      "  Feature 16044: coef=-0.0185\n",
      "  Feature 15356: coef=-0.0178\n",
      "  Feature 31511: coef=-0.0169\n",
      "  Feature 6464: coef=-0.0153\n",
      "  Feature 30656: coef=-0.0098\n",
      "  Feature 17894: coef=-0.0074\n",
      "  Feature 23346: coef=-0.0074\n",
      "  Feature 9185: coef=-0.0068\n",
      "  Feature 31145: coef=-0.0062\n",
      "  Feature 21307: coef=-0.0061\n",
      "  Feature 9329: coef=-0.0061\n",
      "  Feature 11954: coef=-0.0059\n",
      "  Feature 18511: coef=-0.0055\n",
      "  Feature 40531: coef=-0.0054\n"
     ]
    }
   ],
   "source": [
    "# View top peptidoform features\n",
    "num_feats = 20\n",
    "coefs = np.abs(clf.coef_).ravel()\n",
    "top20 = np.argsort(coefs)[::-1][:num_feats]\n",
    "print(\"Top 20 features:\")\n",
    "for idx in top20:\n",
    "    print(f\"  Feature {idx}: coef={clf.coef_.ravel()[idx]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
